---
{"dg-publish":true,"permalink":"/日常学习/技术学习/大模型从零开始/","tags":["Programming🖥️"],"noteIcon":"1","created":"2024-03-09T19:14:40.497+08:00","updated":"2024-03-11T15:45:52.492+08:00"}
---


## 模型结构

> [!summary] 本质上这类问题是考基础，现有模型都是在标准的 Transformer 结构上修补。

-   注意力机制
    -   Transformer 注意力机制究竟是学到了什么
    -   注意力机制的计算公式，一定要这样计算吗
    -   Transformer 为什么使用多头注意力机制，分析时间复杂度
    -   为什么 Q 和 K 使用不同权重矩阵生成，为什么不能使用同一个值进行自身点乘
    -   计算注意力为什么选择点乘而不是加法，从计算复杂度和效果上面讲区别
    -   为什么要对注意力进行 scaled（$\sqrt{d_k}$），公式推导
    -   在计算注意力时如何对 padding 做 mask 操作
    -   为什么在进行多头注意力时需要对每个 head 降维
-   Encoder-Decoder
    -   讲解一下 Encoder 的构造
    -   为什么在获取词向量后需要对矩阵乘以 embedding size 的开方
    -   位置编码如何实现的，意义和优劣
    -   相对位置编码和绝对位置编码
    -   残差结构及其意义
    -   BatchNorm 和 LayerNorm 的区别，为什么选择用 LayerNorm
    -   前馈神经网络简单描述，使用了什么激活函数，公式，有何优劣
    -   Decoder 阶段的多头自注意力和 Encoder 有什么区别，为什么需要 sequence mask
    -   Transformer 的并行化如何体现，Decoder 端可以并行吗
    -   Encoder 是如何和 Decoder 交互的
-   Bert
    -   Bert 和原生 Transformer 的主要区别
    -   为什么会在开头加`[CLS]`，可以有别的替代方案吗
    -   为什么三个 embedding 可以相加（token、segment 和 position）
    -   为什么要用 WordPiece/BPE 这样的 subword Token
    -   Bert 中是如何处理一词多义问题的
    -   Bert 为什么要使用 warmup 的学习率 trick
    -   为什么说 GPT 是单向的而 Bert 是双向的，对比 NTP 和 MLM 任务
    -   prefix LM 和 causal LM 区别是什么？
        -   Prefix LM（前缀语言模型）是一种生成模型，在生成时，前缀语言模型会根据给定的前缀（即部分文本序列，可以是上文，但不一定是上文）预测下一个可能的词。这种模型可以用于文本生成、机器翻译等任务，比如 GPT。
        -   Causal LM（因果语言模型）是一种自回归模型，它只能根据之前的文本生成后续的文本，而不能根据后续的文本生成之前的文本。在训练时，因果语言模型的目标是预测下一个词的概率，给定之前的所有词作为上下文。这种模型可以用于多轮对话、语言建模等任务，比如 ChatGLM。
    -   Bert 变体 Roberta
-   常用优化
    -   GPT3 和 GPT2 的区别，发展史，InstrutGPT 解决对齐问题
    -   flash attention
    -   Multi Query Attention 和 Group Query Attention
    -   位置编码
        -   长度外推问题
        -   旋转位置编码 RoPE
        -   Attention with Linear Biases
    -   分词 tokenizer
    -   Normalization
        -   Layer Norm
        -   RMS Norm
        -   Deep Norm

## 大模型炼丹

> [!summary] 以下问题提纲挈领为主，考察更多是结合任务场景，大多无标准答案，主要靠积累

-   基础理解
    -   [过去三个月，LLaMA 系模型发展如何？指令微调的核心问题又是什么？](https://mp.weixin.qq.com/s/cXPNyOeK9vFjJcgxc_LqZQ)
    -   LLM 的训练目标
        -   最大似然目标，也就是最大化模型生成训练数据中观察到的文本序列的概率。具体来说，对于每个文本序列，模型根据前面的上下文生成下一个词的条件概率分布，并通过最大化生成的词序列的概率，使用梯度下降法等优化算法来优化模型参数。
    -   [涌现能力及其理解](https://zhuanlan.zhihu.com/p/621438653)
        -   两类任务： In Context Learning(Few Shot Prompt)和思维链(CoT)
    -   [为什么现在的大模型大部分是 Decoder only 结构](https://www.zhihu.com/question/588325646/answer/3357252612)
        -   泛化性能（zero shot、few shot）
        -   效率问题，复用 KV-Cache，多轮对话友好
        -   先发优势
        -   多样化解码生成
        -   讨论其它架构的模型：BERT、T5、BART、UNILM
-   常见问题
    -   复读机问题
        -   数据偏差：数据集本身重复度高，多样性不足。
        -   训练目标：自监督学习可能使得模型更倾向于生成与输入相似的文本。
        -   解码方式：贪婪搜索中 beam 和采样中温度的设置。
        -   [Self-Reinforce](https://zhihu.com/question/616130636/answer/3166309896)
    -   长文本处理
        -   分块或分层（段落、句子等）处理，可适当引入重复以确保连贯性。
    -   领域微调后，通用能力遗忘问题
        -   数据方面：保留一定比例的通用数据。
        -   训练方面：领域自适应、对抗学习、强化学习、多任务学习和增量学习（交替使用通用数据集和领域数据集，或逐步引入）。
    -   不同任务场景下的数据集格式
    -   [幻觉问题](https://www.zhihu.com/question/635776684)
        -   什么时候容易产生幻觉
            -   数值混淆，尤其是涉及数字和日期时。
            -   长文本处理，长期依赖关系中可能存在自相矛盾内容。
            -   逻辑推断障碍，模型错误解读了源文本中信息。
            -   上下文与内置知识的冲突，比如领域知识和预训练知识中相同词语的不同意义。
            -   错误的上下文知识，尤其是上下文包含错误假设时，模型可能难以识别。
        -   解决：从数据、训练和推理三个角度讨论。
    -   节省显存
        -   梯度累积 Gradient Accumulation
        -   网络剪枝
        -   量化方法：FP32、FP16 和 BF16。
        -   知识蒸馏：大型预训练模型上进行推理，并使用其输出作为目标标签，来训练一个较小的模型。
-   微调相关
    -   预训练和微调是哪个阶段注入知识的
        -   知识注入是在预训练阶段进行的，预训练模型通过大规模通用数据的训练，学习到了丰富的语言知识和表示能力。
        -   微调的目标是将预训练模型中学到的通用知识和能力迁移到特定任务上，提升模型在目标任务上的性能。
    -   微调是啥
        -   冻结底层权重（通常卷积层） + 替换顶层分类器（通常全连接层） + 解冻部分权重（可选）
    -   [提示微调](https://zhuanlan.zhihu.com/p/635686756)
        -   BitFit
        -   Prefix Tuning
        -   Prompt Tuning
        -   [P-Tuning](https://zhuanlan.zhihu.com/p/635848732)
        -   P-Tuning v2
    -   适配器微调
        -   [Adapter Tuning](https://zhuanlan.zhihu.com/p/636038478)
        -   AdapterFusion
        -   AdapterDrop
        -   [MAM Adapter](https://zhuanlan.zhihu.com/p/636362246)
        -   UniPELT
    -   [LoRA](https://zhuanlan.zhihu.com/p/636215898)
        -   LoRA
        -   AdaLoRA
        -   QLoRA
-   RAG 检索增强生成
    -   解决问题
        -   长尾知识：相对通用和大众的知识结果更准确，剩下的通过增大训练集或者增加参数性价比较低，通过检索知识在上下文给出更加经济。
        -   数据新鲜度：无需重新训练模型就加入更新的知识，因此频繁更新的知识建议单独作为外部知识库。
        -   私有数据：在训练中加入私有数据成本较高，且有隐私信息泄露风险。
        -   来源验证和可解释性：在生成的结果和信息来源之间建立关联，约束生成空间，注意力更加关注知识库中内容，可以缓解幻觉问题。
    -   RAG vs. SFT
    -   索引形式
        -   链式索引
        -   树索引
        -   关键词表索引
        -   向量索引
    -   查询变换
        -   同义改写/扩展查询：生成多个类似的查询，然后各个问题都去找文档，需要去重，并且可能分散注意力，因此这种方法必须要搭配重排序。
        -   查询分解
        -   HyDE：假设文档回复，也就是先生成一个答案，根据这个问答去查询，可能产生幻觉。
    -   检索和重排序：初检索注重效率，选择出 TOPK 召回，然后由重排序（比如时间/时效性）进行精确比对。需要重排序：将一个文档变为向量后势必损失一些信息。另外，重排序后也可以保留尽量少但是高相关的文本，减小上下文长度提升性能。
    -   调优痛点
        -   chunk_size（块大小）和 similarity_top_k 的超参数选择。
        -   重排序，一方面解决相关性问题（确保找到相关的文档，而不是只包含关键词的文档），另一方面缓解中间丢失问题（模型注意力基本集中于开头和结尾的信息）。
        -   检索策略选择
            -   Basic retrieval from each index：基础检索，向量/关键词/结构化字段值。
            -   Advanced retrieval and search：高级检索，查询权重/句子级别/最大边际相关（考虑结果多样性和查询相关性）。
            -   Auto-Retrieval：自动检索，自动选择合适的策略和参数。
            -   Knowledge Graph Retrievers：知识图谱检索，适用于百科等场景。
            -   Composed/Hierarchical Retrievers：复合/层次检索，比如 BM25-SVM 复合检索器。
        - 格式解析，尤其是在需要特定格式输出的场景。
        - 
    -   Graph RAG
-   LangChain 与向量数据库
-   思维链
-   强化学习 RLHF
-   分布式训练
-   Agent
-   AIGC Security
