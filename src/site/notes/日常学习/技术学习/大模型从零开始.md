---
{"dg-publish":true,"permalink":"/日常学习/技术学习/大模型从零开始/","tags":["Programming🖥️"],"noteIcon":"1","created":"2024-03-09T19:14:40.497+08:00","updated":"2024-03-20T14:39:12.974+08:00"}
---


## 模型结构

> [!summary] 本质上这类问题是考基础，现有模型都是在标准的 Transformer 结构上修补。

### 注意力机制

-   Transformer 注意力机制究竟是学到了什么
-   注意力机制的计算公式，一定要这样计算吗
-   Transformer 为什么使用多头注意力机制，分析时间复杂度
-   为什么 Q 和 K 使用不同权重矩阵生成，为什么不能使用同一个值进行自身点乘
-   计算注意力为什么选择点乘而不是加法，从计算复杂度和效果上面讲区别
-   为什么要对注意力进行 scaled（$\sqrt{d_k}$），公式推导
-   在计算注意力时如何对 padding 做 mask 操作
-   为什么在进行多头注意力时需要对每个 head 降维

### Encoder-Decoder

-   讲解一下 Encoder 的构造
-   为什么在获取词向量后需要对矩阵乘以 embedding size 的开方
-   [位置编码](https://zhuanlan.zhihu.com/p/454482273)
    -   Transformer 并行计算，每个 token 彼此独立，也就是输入是无序的，所以需要位置编码提供位置信息。
    -   位置编码的实现
        -   用整型标记：模型可能会遇到比训练序列更长的输入，不利于泛化，且长度越长编码值会很大。
        -   用 $[0, 1]$ 标记：当序列长度不同时，token 间的相对距离不一样。
        -   用二进制编码：编码出来的位置向量，处在一个离散的空间中，不同位置间的变化是不连续的，无法使用位置向量来表示浮点型。
        -   需要有界又连续的函数：三角函数（sin）满足条件，通过频率控制 sin 函数的波长，越往右走（也就是越低位）波长越大，对变化越不敏感，也就是需要更高精度控制。但是仍然有一个问题，sin 是周期函数，因此从纵向（token 序列）来看，如果函数的频率偏大，引起波长偏短，则不同 t 下的位置向量可能出现重合的情况，所以在原论文中选用了一个非常小的值作为频率，尽可能拉长波长。
        -   使用 sin 已经实现了位置向量唯一、有界且可泛化（周期），现在还需要不同位置的位置向量可以通过线性变换得到。因此改为每个 token 位置向量中两两一组，sin 和 cos 交替出现，线性变换就由旋转实现， $\Delta t$ 时刻相当于旋转对应的角度。
    -   位置编码的性质
        -   两个位置编码的点积仅取决于偏移量 $\Delta t$ 。
        -   位置编码的点积具备无向性，即 $PE_t^T * PE_{t+\Delta t} = PE_t^T * PE_{t-\Delta t}$ 。
        -   综上两条，也就是位置编码的点积只能表示距离，无法表示方向。
-   残差结构及其意义
-   BatchNorm 和 LayerNorm 的区别，为什么选择用 LayerNorm
-   前馈神经网络简单描述，使用了什么激活函数，公式，有何优劣
-   Decoder 阶段的多头自注意力和 Encoder 有什么区别，为什么需要 sequence mask
-   Transformer 的并行化如何体现，Decoder 端可以并行吗
-   Encoder 是如何和 Decoder 交互的

### Bert

-   Bert 和原生 Transformer 的主要区别
-   为什么会在开头加`[CLS]`，可以有别的替代方案吗
-   为什么三个 embedding 可以相加（token、segment 和 position）
-   为什么要用 WordPiece/BPE 这样的 subword Token
-   Bert 中是如何处理一词多义问题的
-   Bert 为什么要使用 warmup 的学习率 trick
-   为什么说 GPT 是单向的而 Bert 是双向的，对比 NTP 和 MLM 任务
-   prefix LM 和 causal LM 区别是什么？
    -   Prefix LM（前缀语言模型）是一种生成模型，在生成时，前缀语言模型会根据给定的前缀（即部分文本序列，可以是上文，但不一定是上文）预测下一个可能的词。这种模型可以用于文本生成、机器翻译等任务，比如 GPT。
    -   Causal LM（因果语言模型）是一种自回归模型，它只能根据之前的文本生成后续的文本，而不能根据后续的文本生成之前的文本。在训练时，因果语言模型的目标是预测下一个词的概率，给定之前的所有词作为上下文。这种模型可以用于多轮对话、语言建模等任务，比如 ChatGLM。
-   Bert 变体 Roberta

### 常用优化

-   GPT3 和 GPT2 的区别，发展史，InstrutGPT 解决对齐问题
-   flash attention
-   Multi Query Attention 和 Group Query Attention
-   位置编码
    -   长度外推问题
    -   旋转位置编码 RoPE
    -   Attention with Linear Biases
-   分词 tokenizer
-   Normalization
    -   Layer Norm
    -   RMS Norm
    -   Deep Norm

## 大模型炼丹

> [!summary] 以下问题提纲挈领为主，考察更多是结合任务场景，大多无标准答案，主要靠积累

### 基础理解

-   [过去三个月，LLaMA 系模型发展如何？指令微调的核心问题又是什么？](https://mp.weixin.qq.com/s/cXPNyOeK9vFjJcgxc_LqZQ)
-   LLM 的训练目标
    -   最大似然目标，也就是最大化模型生成训练数据中观察到的文本序列的概率。具体来说，对于每个文本序列，模型根据前面的上下文生成下一个词的条件概率分布，并通过最大化生成的词序列的概率，使用梯度下降法等优化算法来优化模型参数。
-   [涌现能力及其理解](https://zhuanlan.zhihu.com/p/621438653)
    -   两类任务： In Context Learning(Few Shot Prompt)和思维链(CoT)
-   [为什么现在的大模型大部分是 Decoder only 结构](https://www.zhihu.com/question/588325646/answer/3357252612)
    -   泛化性能（zero shot、few shot）
    -   效率问题，复用 KV-Cache，多轮对话友好
        -   [KV-Cache](https://zhuanlan.zhihu.com/p/686183300)：保存了 K 和 V 矩阵投影和每层向量的乘积结果，在计算注意力时空间换时间。成立的条件是每一个 token 的输出只依赖于它自己以及之前的输入，与之后的输入无关。Bert 就不符合这个条件，另外对位置编码有特别设计，每次增加新的 token 后会改变同一 token 位置编码的 LLM 也不符合。
    -   先发优势
    -   多样化解码生成
    -   讨论其它架构的模型：BERT、T5、BART、UNILM

### 常见问题

-   复读机问题
    -   数据偏差：数据集本身重复度高，多样性不足。
    -   训练目标：自监督学习可能使得模型更倾向于生成与输入相似的文本。
    -   解码方式：贪婪搜索中 beam 和采样中温度的设置。
    -   [Self-Reinforce](https://zhihu.com/question/616130636/answer/3166309896)
-   长文本处理
    -   分块或分层（段落、句子等）处理，可适当引入重复以确保连贯性。
-   领域微调后，通用能力遗忘问题
    -   数据方面：保留一定比例的通用数据。
    -   训练方面：领域自适应、对抗学习、强化学习、多任务学习和增量学习（交替使用通用数据集和领域数据集，或逐步引入）。
-   不同任务场景下的数据集格式
-   [幻觉问题](https://www.zhihu.com/question/635776684)
    -   什么时候容易产生幻觉
        -   数值混淆，尤其是涉及数字和日期时。
        -   长文本处理，长期依赖关系中可能存在自相矛盾内容。
        -   逻辑推断障碍，模型错误解读了源文本中信息。
        -   上下文与内置知识的冲突，比如领域知识和预训练知识中相同词语的不同意义。
        -   错误的上下文知识，尤其是上下文包含错误假设时，模型可能难以识别。
    -   解决：从数据、训练和推理三个角度讨论。
    -   [模型遗忘](https://zhuanlan.zhihu.com/p/665691828)：用于版权、隐私保护和偏见信息处理。模型的遗忘不是完全对目标信息返回为空，而是出现幻觉，比如哈利波特的角色信息被遗忘，返回他是一个导演作家等。
        -   实际策略：先对要遗忘的信息构建特定数据集，使其对该文本的预测更加倾向于原始内容。也就是改变最开始模型的相关标记，从而方便下一步，使用模型自身的预测能力，为每个标记生成替代标签。
-   节省显存
    -   梯度累积 Gradient Accumulation
    -   网络剪枝
    -   量化方法：FP32、FP16 和 BF16。
        -   fp16 中 5 位用来表示指数位（除去全 0 和全 1，一共是 $2^5-2=30$，也就是可以表示$[-14,+15]$），10 位用来表示小数位，剩下 1 位是符号位。其中指数位全 0 表示非规格数（+0、-0 和极其接近 0 的数字），全 1 表示特殊数（小数位全 0 表示 Inf，符号位确定+Inf 和-Inf，小数位不全为 0 表示 NaN），所以 fp16 的最大绝对值是 $(1+\frac{1023}{1024})*2^{15}=65504$，而最小正值是$\frac{1}{1024} *2^{-14}=2^{-24}=5.96E−8$。
        -   fp32 和 fp16 基本一致，符号位 1 位，指数位 8 位，尾数位 23 位，因此 fp32 的动态范围为 $(1.4E-45$ ~ $3.40E38)$。
        -   bf16 则是保留了和 fp32 一样的指数位，也就是在尾数位做了截断，只剩下 7 位尾数位，因此就是牺牲了精度来换取几乎和 fp32 一样大的取值范围，避免 fp16 的溢出问题。bf16 的最大绝对值是 $(1+\frac{127}{128})*2^{127}$，而最小正值是$\frac{1}{128} *2^{-126}=2^{-133}$。bf16 的动态范围为 $(9.2E-41$ ~ $3.38E38)$。
        -   为什么要使用半精度
            -   占用内存更少，可以选用更大的 batch_size。
            -   训练时通信量大幅降低（尤其是多机多卡），加快数据流通，大幅降低等待时间。
        -   混合精度
            -   不能全部替换为半精度：**溢出问题**（超过正负最大值）和**舍入误差**（比最小正值小的加减被舍去）
            -   权重的高精度备份：使用 fp32 权重作为精确的 “主权重 (master weight)”进行备份，而其他所有值（weights，activations， gradients）均使用 fp16 进行计算以提高训练速度，最后在梯度更新阶段再使用半精度的梯度更新单精度的主权重，这样当很小的梯度乘上学习率后要跟权重（fp32 的）做运算时，就不会被舍弃了。
            -   Loss Scale：大部分的梯度值都很小，因此该方法通过让梯度乘一个 scale，从而整个分布右移、占据更多 fp16 可表示的范围。
            -   算数精度：神经网络主要涉及三种计算，向量点乘（常见于全连接层），归约（Reduction，减少张量元素，常见于归一化和池化层等），点运算（pointwise，常见于 ReLU、tanh 等激活函数），其中向量点乘中加法使用 fp32 完成，存储结果则使用半精度，reduction 也要用 fp32 来做，但以半精度方式存储；而 pointwise 的运算主要受到 memory-bandwidth 限制（计算简单且可以良好并行化），因此它们是以单精度还是半精度运算，都不影响计算速度，所以单、半精度均可。
        -   由于 fp16 的范围有限，因此在训练中很容易出现溢出问题，因此一般**在训练时都使用 bf16**，若要使用 fp16 则通常搭配 loss scale 操作。而 bf16 能够和 fp32 有相近的范围，且由于表示范围略小于 fp32，可以起到**隐式正则化**的作用，避免过拟合（训练时参数通常呈现幂律分布，在 bf16 中,outlier 值由于超出了表示范围而被 clipped，且大部分值仍在范围内，不会明显降低模型性能）。而在推理时，由于 fp16 精度更高，参数范围也通常趋于稳定，所以通常都直接使用 fp16。
        -   由于额外增加的反量化和重量化操作的存在，推理和训练一般都不会节省时间，反而会增加时间，因此也勉强可以算是一个时间换空间的例子。
        -   半精度仍然不够的情况下，也可以进行 8bit 或 4bit 量化。
        -   TF32：由 1 个符号位，8 位指数位（对齐 FP32）和 10 位小数位（对齐 FP16）组成，实际只有 19 位。在性能、范围和精度上实现了平衡，用于替代 FP32。
        -   NF4：将浮点权重在量化的同时归一化到以 0 为均值、标准差在 $[-1,1]$ 范围内的正态分布上。首先将浮点权重参数离散化为 4 位整数值，然后计算正态分布固定期望值，最后标准化，于 QLoRA 首次使用。
    -   知识蒸馏：大型预训练模型上进行推理，并使用其输出作为目标标签，来训练一个较小的模型。

### 微调相关

-   预训练和微调是哪个阶段注入知识的
    -   知识注入是在预训练阶段进行的，预训练模型通过大规模通用数据的训练，学习到了丰富的语言知识和表示能力。
    -   微调的目标是将预训练模型中学到的通用知识和能力迁移到特定任务上，提升模型在目标任务上的性能。
-   微调是啥
    -   冻结底层权重（通常卷积层） + 替换顶层分类器（通常全连接层） + 解冻部分权重（可选）
-   [提示微调](https://zhuanlan.zhihu.com/p/635686756)
    -   BitFit
    -   Prefix Tuning
    -   Prompt Tuning
    -   [P-Tuning](https://zhuanlan.zhihu.com/p/635848732)
    -   P-Tuning v2
-   适配器微调
    -   [Adapter Tuning](https://zhuanlan.zhihu.com/p/636038478)
    -   AdapterFusion
    -   AdapterDrop
    -   [MAM Adapter](https://zhuanlan.zhihu.com/p/636362246)
    -   UniPELT
-   [LoRA](https://zhuanlan.zhihu.com/p/636215898)
    -   主要思想：冻结预训练模型的参数，并选择用 A 和 B 矩阵来代替，在微调下游任务的时候，只更新 A 和 B。
    -   优势：节省资源、共享模块（替换 AB 矩阵快速切换下游任务，即**可插拔**）、不会引入推理延迟（全量微调后需要重新读写内存、缓存失效、针对参数优化失效）、和其它许多方法正交（如 Prefix Tuning）。
    -   基础模型对 LoRA 训练影响较大，增大数据量和参数量可以提升效果，但是并不是仅通过提升数据量和参数量就可以让本来学习力更低的模型效果超越学习力更强的模型。
    -   [LoRA](https://zhuanlan.zhihu.com/p/646831196)
        -   对 A 矩阵随机高斯初始化，对 B 矩阵零初始化，保证**训练开始时旁路为 0 矩阵**，不会在开始引入噪声，理论上二者初始化情况也可以交换，并没有明显差异。
        -   另外有缩放因子$\frac{\alpha}{r}$，其中秩 $r$ 就是信息量的表现形式。已知 SVD（奇异值分解）能够关注到最强调的几项特征，而 $W$ 代表旧知识，对其作 SVD 没有意义，$\Delta W$ 代表新知识，但是该项并不是确定的，只有全参微调后才能确定。因此最终只能设置**秩为超参**，让模型自行学习低秩矩阵 A 和 B。除此之外， $r=64$ 的前八个特征并不一定和 $r=8$ 完全相同，模型会尽可能往信息最丰富的维度学，但不一定学出来的就是真实的 top $r$ 。因此我们在模型的不同部分，比如 $W_q$ 和 $W_v$ ，也可能采用不同的秩。
        -   $\alpha$ 则一般设置为第一次实验时的 $r$ ，第一次的 $r$ 通常会设置较大，从而尽可能更近似 $\Delta W$，此时缩放因子为 1，意味着假定 LoRA 微调效果和全参微调持平。而后自然会逐渐减小 $r$ ，此时缩放因子随之增大，也就是保持新知识对模型权重的影响。除此之外， $r$ 较小意味着精炼但不全面，梯度下降方向更加确定，可以适当放大影响；而 $r$ 较大意味着全面而有冗余或噪声，适当减小步伐也是合理的。
        -   正常情况下，输入的信息因为注意力机制会关注重要信息和省略无意义信息而导致信息冗余，体现在矩阵上就是**不满秩**，因此使用这种方式可以大幅降低参数计算量。同时由于噪声的影响，可能在某些场景下效果甚至能超过全量微调。
    -   [AdaLoRA](https://zhuanlan.zhihu.com/p/657130029)
        -   主要思想：LoRA 中对不同模块使用相同的秩，且秩设置不变均不合理，所以总体目标就是**动态调整不同模块下的秩**。微调高层参数（比如 FFN）的效果会比微调底层参数（比如 attention）的效果更好。
        -   LoRA 使用了 $\Delta W=U\Sigma V^T\approx BA$ 近似，而 AdaLoRA 则直接使用三个矩阵 $P, \Lambda, Q$ 去近似，其中中间 $\Lambda$ 矩阵是对角矩阵，初始化为 0，另外二者随机高斯初始化，原因同样是保证训练开始时无噪声。
        -   实际计算中， $\{P_{*,i}, \sigma_{i}, Q_{i,*}\}$ 组成三元组，$P$ 表示第 $i$ 列，$Q$ 表示第 $i$ 行，根据重要性分数，将不重要的三元组中的 $\sigma$ 置为 0，相当于 mask，**不是直接删除**的原因是，模型学习是探索的过程，在一开始模型认为不重要的三元组，在后续过程中模型可能会慢慢学到它的重要性。能够保留奇异向量，也是 AdaLoRA 表现优于 LoRA 的一个原因。
        -   三元组的重要性分数 = $\Lambda$ 的重要性分数 + $P$ 矩阵中所有元素重要性分数的均值 + $Q$ 矩阵中所有元素重要性分数的均值。取均值的原因，是不希望参数量影响到重要性分数。而单参数的重要性分数则定义为参数权重和损失函数在该参数上的梯度乘积的绝对值，然后加以 momentum 消除不同 batch 上的波动，也就是减轻单个 batch 样本带来的重要性的评估误差，对于这个引入的不确定性 $U$ ，在计算时也考虑平滑后的差异，不可忽略真实的波动情况。
        -   筛选重要三元组的策略称为 top_b，在训练刚开始的过程中逐渐增大 top_b，也就是加秩，让模型充分探索，到后期开始逐渐降低 top_b，最后以相对稳定的 top_b 进行训练，整个过程和 warmup 类似。
        -   AdaLoRA 的损失函数由两部分组成，一部分是正常的训练集损失函数，即预测值和真实标签之间的差距，而另一部分是 $P$ 和 $Q$ 和**满足正交矩阵性质**的差异，因为真实的 SVD 中，$U$ 和 $V$ 都是正交矩阵。由于 LoRA 在训练时没有引入任何和 SVD 性质相关的约束，所以往往 AdaLoRA 比之能够具有更好的效果，训练时能够更加稳定，泛化性能更好。
    -   [QLoRA](https://zhuanlan.zhihu.com/p/666234324)
        -   NF4：四位标准浮点数量化，其中结合了**分位数量化**（分为若干相等块，使用累积分布函数的反函数简化计算）和**分块量化**（将张量分成若干个块，每个块都有独立的量化常数，也就是该块最大值，对其进行归一化，反量化就借助其和存储的量化后的低精度值恢复到高精度值，分块的优势在于不容易出现极端值，导致整体量化后极大或极小）。关于 0 的处理是正数取 9 个值，负数取 8 个值，均会取到零点，然后去重，也就是确保 0 的映射值是 0，并用满 4 位数据类型的全部 16 位。
        -   双重量化：由上得知，在模型保存时，除了保存量化后的低精度值，也要保存对应的量化常数。而这个常数是 FP32 高精度值，会额外占用较高显存，因此需要对这个常数也做一次 8bit 量化，QLoRA 以每 256 个量化常数为一组。同样，在反量化时，也因此需要两次操作。
        -   分页优化：当显存不足时，将保存的部分梯度检查点转移到 CPU 内存上，和计算机的内存数据转移到硬盘上的常规内存分页类似，牺牲时间换空间，主要是解决显存**峰值占用**问题，论文的创举是在消费级显卡上训练 33B 模型，在此场景下应该是必需的。是对梯度检查点的进一步优化，梯度检查点是在牺牲显存保存前向传播的激活值，和节省显存重新依照损失函数计算激活值之间的权衡。丢失部分激活值，有保存的就用，没有就重新计算。
        -   QLoRA 也在原参数一侧添加了一个与原参数并行的低秩适配器，它的精度是 BF16。也就是说，QLoRA 有一个 4NF 的存储数据类型和 16BF 的计算数据类型，在计算前向和反向传播时通过反量化为 BF16 计算。
        -   QLoRA 主要关注点都在尽可能节省显存，而在微调训练方面几乎和 LoRA 一致。

### RAG 检索增强生成

-   解决问题
    -   长尾知识：相对通用和大众的知识结果更准确，剩下的通过增大训练集或者增加参数性价比较低，通过检索知识在上下文给出更加经济。
    -   数据新鲜度：无需重新训练模型就加入更新的知识，因此频繁更新的知识建议单独作为外部知识库。
    -   私有数据：在训练中加入私有数据成本较高，且有隐私信息泄露风险。
    -   来源验证和可解释性：在生成的结果和信息来源之间建立关联，约束生成空间，注意力更加关注知识库中内容，可以缓解幻觉问题。
-   RAG vs. SFT
    -   数据方面，RAG 能够确保数据保持最新，在面对频繁变更的数据时成本消耗也偏低。
    -   生成方面，RAG 不容易产生幻觉，但是无法保证形成特定风格的输出，响应阶段相对透明（比如可以提供检索的匹配度）。
    -   实现方面，RAG 关注的核心是检索策略以及数据的存取和更新，SFT 则是数据集的构建、微调目标定义和计算资源准备。
-   索引形式
    -   链式索引
    -   树索引
    -   关键词表索引
    -   向量索引
-   查询变换
    -   同义改写/扩展查询：生成多个类似的查询，然后各个问题都去找文档，需要去重，并且可能分散注意力，因此这种方法必须要搭配重排序。
    -   查询分解：将一个查询分解为多个子问题。
    -   HyDE：假设文档回复，也就是先生成一个答案，根据这个问答去查询，可能产生幻觉。
-   检索和重排序：初检索注重效率，选择出 TOPK 召回，然后由重排序（比如时间/时效性）进行精确比对。需要重排序：将一个文档变为向量后势必损失一些信息。另外，重排序后也可以保留尽量少但是高相关的文本，减小上下文长度提升性能。
-   调优痛点
    -   chunk_size（块大小）和 similarity_top_k 的超参数选择。
    -   重排序，一方面解决相关性问题（确保找到相关的文档，而不是只包含关键词的文档），另一方面缓解中间丢失问题（模型注意力基本集中于开头和结尾的信息）。
    -   检索策略选择
        -   Basic retrieval from each index：基础检索，向量/关键词/结构化字段值。
        -   Advanced retrieval and search：高级检索，查询权重/句子级别/最大边际相关（考虑结果多样性和查询相关性）。
        -   Auto-Retrieval：自动检索，自动选择合适的策略和参数。
        -   Knowledge Graph Retrievers：知识图谱检索，适用于百科等场景。
        -   Composed/Hierarchical Retrievers：复合/层次检索，比如 BM25-SVM 复合检索器。
    -   格式解析，尤其是在需要特定格式输出的场景。
    -   LLamaIndex 支持并行化处理，尤其是在系统处理大量数据的场景。
    -   结构化数据和 PDF 等文件处理，采用符号推理和文本推理结合（多数投票机制）。另外，也可以尝试使用 pdf2htmllex 将 PDF 转换为 HTML
    -   备用模型
    -   安全性，对抗提示注入，处理不安全的输出，防止敏感信息的泄露，相关工具有 LLama Guard。
-   Graph RAG

### LangChain 与向量数据库

### 思维链

### 强化学习 RLHF

### 分布式训练

### Agent

### AIGC Security
