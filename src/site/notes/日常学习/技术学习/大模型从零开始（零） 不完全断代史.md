---
{"dg-publish":true,"permalink":"/日常学习/技术学习/大模型从零开始（零） 不完全断代史/","title":"大模型从零开始（零） 不完全断代史","tags":["LLM","保持期待"],"noteIcon":"1","created":"2025-02-22T21:55:25.761+08:00","updated":"2025-12-26T10:01:35.132+08:00"}
---


## 前奏 2021 及之前

*前大模型时代，绝大多数论文与研究还是在模型架构（排列组合）和训练方式（任务设计、损失函数等）上进行各种尝试，然而必要的铺垫已逐步出现。*

### 1980s

自然语言处理（NLP）正式开始被系统性探索研究。

### 1997-2014

LSTM（1997）：单元状态、隐藏状态、输入门、输出门和遗忘门。
Seq2Seq 模型（2014）：广泛应用于机器翻译、语音识别和文本摘要等任务。

### 2017-2021

Transformer（2017）：Attention is All You Need，当时还鲜有人能想到，它将在 NLP 攻城略地，甚至一统 NLP 和 CV 两大江湖。
BERT（2018）：仅使用编码器的双向编码器表示模型，完形填空与下一句预测。
GPT（2018）：预测下一个词任务，和 BERT 的恩怨情仇。
T5（2019）：统一转化 NLP 任务为文本到文本的形式。
GPT2（2019）：Zero-Shot，提示工程/ICL 雏形已经出现。
GPT3（2020）：175B 参数，隐藏的 Scaling Law 大手已经开始发力。
ViT（2020）：Google 发布 An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale，简单且扩展性强的将 Transformer 运用于视觉任务的方案。
CLIP（2021）：对比学习配对图像和自然语言文本，奠定多模态 AI 的研究和应用。

## 序曲 2022

*2022 年 11 月 30 日，ChatGPT 的发布正式降低了普通人使用 AI 的门槛，将 GPT3.5 产品化后毋庸置疑点燃了学术界和工业界的热潮，成为了大模型及相关衍生技术规模化应用的序曲。*

ChatGPT/InstructGPT：在 GPT3 的基础上 SFT+RM+PPO 三步走，更真实符合人类偏好的输出为产品化铺好了道路。但是显然那个时候的模型还很粗糙，例如无法防御有害的 Prompt，也容易在简单的问题上长篇大论（长输出通常赢得更多奖励）。
Whisper：OpenAI 发布的语音识别模型，此后依旧是在响应时间和价格上持续竞争。

Flash Attention：Fast and Memory-Efficient Exact Attention with IO-Awareness，此后在计算优化中扮演了重要角色的 Flash Attention 在 2022 年 6 月推出，才发现这竟然还早于 ChatGPT，v1 版本主要是分块计算减少访存开销和优化注意力计算的算法流程。此后又连续迭代了几个版本，除了打好补丁，更多关注的是底层硬件更新带来的相关优化适配。
LoRA：低秩适应，起初被用于微调扩散模型，此后被广泛应用于大模型，并衍生出了 AdaLoRA、QLoRA 等方案。

Midjourney：V3 版本发布时开始引发广泛关注的文生图模型，依托 Discard 频道，获得一定关注量的时间甚至比 ChatGPT 发布还要早几个月。
Stable Diffusion：2022 年 12 月下旬发布，扩散模型，开源可本地部署是它的优势。
现在回顾，无论是 MidJourney 还是 SD 在那个时代都还主要是被用于娱乐，生成足够精致的图片需要反复的打磨和堪称魔法咒语级别的 Prompt。

## 间章 2023

*ChatGPT 的成功让更多的人看到了机会，不少追随者率先成为了提示工程魔法师，新的模型层出不穷，亦有不少研究者仍在蓄势，探索与其它原有技术的融合。*

Claude：ChatGPT 的强有力竞争者，刚推出的时候主打的就是 ChatGPT 广为诟病的无害性和更符合价值观（~~显然是西方世界~~），也就是说在文本创作方面更合适，但是也更容易出现偏见或胡说八道（幻觉）。另外让人印象深刻的就是激进的封号策略，稍不留神就被封了还不是暂时而是永久的。
LLaMA/GLM/Qwen：开源先驱，当年真正的 OpenAI，不过刚推出来的版本效果都一般。这个时候数据的重要性已经开始逐步凸显。
Mistral：在年末发布了首个开源 MoE 模型，推动了新的路线之争。
Kimi Chat：主打大海捞针的长文本能力，在 2024 年收获了较高的热度，创意生成相对弱一些，但是很擅长开卷考试。
[ChatGPT-Prompts](https://github.com/PlexPt/awesome-chatgpt-prompts-zh)：风靡一时的提升工程仓库。

Poe/ChatBox：聚合 AI 服务工具，前者算是先驱但是付费，后者是开源可自配置。刚开始用 Poe 的原因主要是 Claude 把号封了，ChatGPT 也时不时因为 IP 污染而降智，到 2025 年已经很少打开了，这玩意也是注册越早赠送配额越多（当然后面绝大多数工具或服务都是这样）。以及还有一个特性是提供丰富的用户社区自建 GPTs，恰好 2023 也是提示工程最火的时代。
New Bing：大模型应用产品化的又一尝试，互联网的信息本身也良莠不齐，因此搜索引擎同 AI 的结合确实比较符合直觉。可惜其兴也勃焉，其亡也忽焉，热度只停留在了 2023。可能与跟不上模型快速迭代，N 轮所谓的“安全”加强（创造力显著降低），使用限制（想起来了 Github 当年数不胜数的 new bing 逆向工程项目）以及网络条件等因素有关。不过还是具备了一些特性，例如将温度配置开放给用户，对 emoji 经常情有独钟。
Milvus：2019 年开源，向量数据库们因为 RAG 的浪潮而焕发新生，Milvus 是使用较为广泛的一个。
Ollama：本地大模型搞起来，不过对日常使用的话意义不太大，除非涉及隐私或服务状态不可用。
[AI Video Search Engine (AVSE)](https://avse.vercel.app/)：RAG Youtube 视频，相对复杂的任务，应该是主要增加利用了音频信息和缩略图。

GQA：Google Research 提出分组查询注意力，是原本 MHA 和 2019 年提出的 MQA 的中庸选择。
Page Attention：主攻推理瓶颈，力争打满显存，提出者当年一定很擅长操作系统和计算机组成原理这两门课。

Mamba：新结构的尝试，本人没有深入研究了解过，可惜并没有打破现有格局，倒是让不少跟随者有幸做出了一些能够帮助毕业的工作。
LLaVA：新的多模态大模型，特征对齐与端到端微调。

## 波澜 2024

*进入 2024，提示工程的热度逐渐褪去，Scaling Law 的魔咒也开始失效，各家厂商都开始探索打补丁提高效果的方案，因此也可以看作一个此起彼伏的波澜期。*

LLaMA3.1 405B：非 MoE 结构，其实训得效果不是想象中的好，训练过程中处理各类异常也极其折磨，加之有质量的数据基本采集干净，未来模型上限提升需要寻找新的方案。
DeepSeek-V2/V3：激进的 MoE 发展方向，扩展到 256 个专家 671B，坚持使用 MLA，提出多 token 预测（MTP）训练目标。
LLM Reasoning（o1/MCTS/rStaR 等）：可解释性与 Post-Training 的相关研究，爆搜换取更大可能的问题解决能力。这样的选择可能也跟 Scaling Law 发展两三年，逐渐乏力，保持一定质量的数据（互联网的数据是有限且良莠不齐的）已经用尽相关。
BGE：BAAI 发布的开源 embedding 以及 rerank 模型，支持多语言，尤其是在中文上相比先前的模型取得了非常不错的效果。

LLama-Factory：模型微调和 RLHF 框架，提供 webui，简单易上手，支持 flashattn 等多种优化，持续更新维护中。
Unsloth：使用 OpenAI 的 Triton 对模型的计算过程进行重写，大幅提升模型的训练速度，降低训练中的显存占用，主打的就是低显存长上下文训练。

Emergent Mind/ChatPaper：搜索、追踪 arxiv 上计算机不同领域的论文，然后基于论文进行问答。
LangChain：和 ChatGPT 几乎同步出现，在新年伊始发布了第一个稳定版本，目标是未来可能的 Agent 大规模应用，但是实际较为臃肿，需要一定的上手成本，如果使用 ReAct 那么负载开销不容忽视。
Dify/Coze/FastGPT 等：比起模型自身 Function Calling 较高的开发集成难度，dify/coze 实现了低代码 AI 应用搭建的尝试，按需引入模块化插件，专注工作流设计本身，个人或小团队效率提升必备，大规模场景使用仍需更多实验和测试。
Cursor/Trae：AI IDE，集成度相比 Copilot + IDE 的方式高了很多，可以根据仓库级文件内容信息产生更贴切的代码，但是 cursor 价格昂贵，支持 Trae 打败 cursor 的同时也担心自己离失业越来越近，未来对设计和业务的直觉将更加重要，岗位职能或许将进一步模糊，需要的是能发挥 AI 最大作用的六边形战士。以及，现在 Trae 好像还是因为在 beta 测试所以免费，希望福利能持续久一点。

GPT4o：推动了多模态大模型的广泛应用，支持图片、文件、链接读取和代码生成数据分析图，在 2024 年大多数时间实现统治力，此后各家厂商陆续跟进。
豆包：年中发布，产品化比较成功的国产模型，支持多模态，经典应用性价比策略，较为水桶的国产模型。
Sora/可灵等：文生视频模型，OpenAI 宣传了以后隔了多个月才发布，在此期间国内厂商迅速跟进，不过文生视频的效果实践仍旧有很长的路要走。

## 奏鸣 2025 - 未来

*年初发布的 DeepSeek-R1 选择了另一种探索模型上限的方案，RL 不再是解决无害性和讨好人类用户的工具，势必其它厂商还会有更多的尝试，例如 R1 的方案在 CV 等领域的融合，深度思考的效率提升，问题难度和不同模型的适配，除此之外现有流程中不少环节仍充斥着粗糙的实现与设计。时间还长，我们持续期待。*

DeepSeek-R1：新的探索上限的思路，大模型 RL，小模型蒸馏，开源实现推动共进。强大的文本创造力是用户量和留存率的保证，即使可用性偏低，即使没有多模态能力，还是能保持高日活。普通用户也许并不需要强大到解决 IMO 国际数学奥林匹克难题的推理能力，降低使用门槛，提高性价比并且能够解决日常问题或许就足够了。
Claude3.7：Claude 这波更新选择继续坚定打造具备最强代码能力的通用模型，不过也能看出来团队内部仍旧对此不够满意，否则可能会被直接命名为 4.0 版本。
ChatGPT4.5：惊人的价格，具体水平等待后续实际评测。
ima/flowith：高度集成 AI 的知识库工具，相比而言的话可能更适合作为信息收集、整合和查询工具，个人笔记到底需要什么程度的 AI 介入，仍旧值得思考。所以我还是先选择 Obsidian+Copilot 插件（自配置嵌入模型和生成模型）。

硅基流动等：提供 API 服务的平台，对于绝大多数人和不涉及隐私的场景，本地部署是不可能实现且没必要的，由于 DeepSeek 的相对低可用性，给这类服务平台带来了衍生机会。另外，在其它工具中（例如 Zotero、沉浸式翻译），廉价且尽可能保持高可用的 API 提供商也不可或缺。

## 回响 2023-？？？？

*大模型显然改变的不只是 NLP 和 CV 两个领域，已经在方方面面都产生回响，例如和硬件的结合（具身智能），例如交通和旅行规划难题，例如 AI4Science，AGI 什么时候真正出现或许并不重要，我们更关注的是每一个领域的乘势发展，甚至是革命。*